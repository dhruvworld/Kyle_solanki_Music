{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop vs Non-Pop Genre Classification\n",
    "**by Kyle Furey & Dhruv Solanki**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfl\n",
    "from tensorflow.keras import callbacks as tfkc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavioral Spotify dataset\n",
    "DATA_PATH = '../data/spotify_final_with_behavior.csv'\n",
    "\n",
    "print('Loading data from', DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "\n",
    "# Define pop-vs-non-pop label using tags/genre (real Spotify metadata)\n",
    "import re\n",
    "\n",
    "pop_keyword_patterns = [\n",
    "    r\"\\bpop\\b\",\n",
    "    r\"dance[- ]?pop\",\n",
    "    r\"electro[- ]?pop\",\n",
    "    r\"synth[- ]?pop\",\n",
    "    r\"teen pop\",\n",
    "    r\"pop rock\",\n",
    "    r\"pop rap\",\n",
    "    r\"latin pop\",\n",
    "    r\"indie pop\",\n",
    "    r\"k[- ]?pop\",\n",
    "    r\"j[- ]?pop\",\n",
    "    r\"c[- ]?pop\",\n",
    "]\n",
    "\n",
    "def is_pop_track(row):\n",
    "    # Genre column now contains the actual genres (was moved from tags column)\n",
    "    text = f\"{row.get('genre', '')}\".lower()\n",
    "    return int(any(re.search(pat, text) for pat in pop_keyword_patterns))\n",
    "\n",
    "df['is_pop_genre'] = df.apply(is_pop_track, axis=1)\n",
    "print('Pop class positive rate:', df['is_pop_genre'].mean())\n",
    "\n",
    "# Define features and target based on pop labels\n",
    "# Enhanced feature set with more numeric features\n",
    "numeric_features = ['spotify_popularity', 'album_release_year', 'tempo_bpm_synth', 'position']\n",
    "cat_feature = 'time_of_day_synth'\n",
    "# REMOVED: genre TF-IDF (data leakage - contains 'pop' which directly indicates target)\n",
    "# text_feature = 'genre'  # Genre column now contains the actual genres (was moved from tags)\n",
    "text_feature = None  # Disabled to prevent data leakage\n",
    "target_column = 'is_pop_genre'\n",
    "\n",
    "# Extract additional features\n",
    "df['is_explicit_binary'] = df['is_explicit'].astype(int)\n",
    "\n",
    "# Extract temporal features from album_release_date\n",
    "df['album_release_date'] = pd.to_datetime(df['album_release_date'], errors='coerce')\n",
    "df['release_month'] = df['album_release_date'].dt.month.fillna(0).astype(int)\n",
    "df['release_decade'] = (df['album_release_year'] // 10 * 10).astype(int)\n",
    "\n",
    "# Create interaction features\n",
    "df['popularity_x_year'] = df['spotify_popularity'] * df['album_release_year']\n",
    "df['tempo_x_year'] = df['tempo_bpm_synth'] * df['album_release_year']\n",
    "\n",
    "# Use derived features if they exist (created by create_derived_features.py)\n",
    "# These are proxy features for audio features (danceability, energy, valence, acousticness)\n",
    "# since Spotify deprecated the audio-features endpoint for new apps\n",
    "derived_features = []\n",
    "if 'is_highly_popular' in df.columns:\n",
    "    derived_features.extend(['is_highly_popular', 'is_moderately_popular', 'popularity_normalized'])\n",
    "# REMOVED: has_pop_genre and genre_count (data leakage - derived from same genre column as target)\n",
    "# if 'has_pop_genre' in df.columns:\n",
    "#     derived_features.extend(['has_pop_genre', 'genre_count'])\n",
    "if 'is_recent' in df.columns:\n",
    "    derived_features.extend(['is_recent', 'is_very_recent'])\n",
    "if 'tempo_is_pop_range' in df.columns:\n",
    "    derived_features.extend(['tempo_is_pop_range', 'tempo_normalized'])\n",
    "if 'is_daytime' in df.columns:\n",
    "    derived_features.append('is_daytime')\n",
    "if 'is_not_explicit' in df.columns:\n",
    "    derived_features.append('is_not_explicit')\n",
    "if 'popular_recent' in df.columns:\n",
    "    derived_features.append('popular_recent')\n",
    "if 'mainstream_pop_signal' in df.columns:\n",
    "    derived_features.append('mainstream_pop_signal')\n",
    "\n",
    "print(f'Using {len(derived_features)} derived features as proxies for audio features')\n",
    "if len(derived_features) > 0:\n",
    "    print(f'Derived features: {derived_features[:5]}...' if len(derived_features) > 5 else f'Derived features: {derived_features}')\n",
    "\n",
    "# Prepare feature sets - include derived features\n",
    "X_num = df[numeric_features + ['is_explicit_binary', 'release_month', 'release_decade', \n",
    "                                'popularity_x_year', 'tempo_x_year'] + derived_features].copy()\n",
    "X_cat = df[[cat_feature]].copy()\n",
    "# X_text = df[text_feature].fillna('')\n",
    "X_text = pd.Series([''] * len(df))  # Empty to prevent data leakage\n",
    "y = df[target_column].astype(int).values\n",
    "\n",
    "# One-hot encode time_of_day_synth\n",
    "X_cat_dummies = pd.get_dummies(X_cat, columns=[cat_feature], drop_first=False)\n",
    "\n",
    "# REMOVED: TF-IDF on genre (data leakage - contains 'pop' which directly indicates target)\n",
    "# tfidf = TfidfVectorizer(max_features=15, ngram_range=(1, 1), min_df=20)\n",
    "# X_tfidf = tfidf.fit_transform(X_text).astype('float32')\n",
    "import scipy.sparse as sp\n",
    "# Create empty TF-IDF matrix (no genre features to prevent leakage)\n",
    "X_tfidf = sp.csr_matrix((len(X_text), 0), dtype='float32')\n",
    "\n",
    "# Scale numeric features on the full dataset\n",
    "scaler = StandardScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "# Build final feature matrix: numeric + one-hot time_of_day + TF-IDF tags\n",
    "X_tab = pd.concat([\n",
    "    pd.DataFrame(X_num_scaled, columns=X_num.columns),\n",
    "    X_cat_dummies.reset_index(drop=True),\n",
    "], axis=1)\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_full = sp.hstack([sp.csr_matrix(X_tab.values.astype('float32')), X_tfidf], format='csr')\n",
    "feature_dim = X_full.shape[1]\n",
    "print('Enhanced feature dimension (tabular + genre TF-IDF):', feature_dim)\n",
    "print('Numeric features:', len(X_num.columns))\n",
    "print('Categorical features (one-hot):', X_cat_dummies.shape[1])\n",
    "print('TF-IDF features (from genre column):', X_tfidf.shape[1])\n",
    "\n",
    "# Create explicit train / validation / test splits (stratified)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X_full, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val_full, X_test_full, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "X_train_np = X_train_full.toarray().astype('float32')\n",
    "X_val_np = X_val_full.toarray().astype('float32')\n",
    "X_test_np = X_test_full.toarray().astype('float32')\n",
    "y_train = y_train_full\n",
    "\n",
    "print('Train / Val / Test sizes:', X_train_np.shape[0], X_val_np.shape[0], X_test_np.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train FFNN for pop genre prediction\n",
    "\n",
    "input_dim = X_train_np.shape[1]\n",
    "print('Input dimension:', input_dim)\n",
    "\n",
    "model = tfk.Sequential([\n",
    "    tfl.Input(shape=(input_dim,)),\n",
    "    tfl.Dense(32, activation='relu'),\n",
    "    tfl.Dropout(0.3),\n",
    "    tfl.Dense(16, activation='relu'),\n",
    "    tfl.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tfk.losses.BinaryCrossentropy(),\n",
    "    metrics=[tfk.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Early stopping on validation loss using held-out validation set\n",
    "callbacks = [\n",
    "    tfkc.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_np, y_train,\n",
    "    validation_data=(X_val_np, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary cross-entropy')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print('Evaluating on test set ...')\n",
    "\n",
    "probs = model.predict(X_test_np).ravel()\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "print('\\nClassification report (0 = non-pop, 1 = pop):')\n",
    "print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    print(f'ROC AUC: {auc:.3f}')\n",
    "except Exception as e:\n",
    "    print('Could not compute ROC AUC:', e)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Non-pop', 'Pop']).plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras training & validation accuracy curves\n",
    "\n",
    "if 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Keras FFNN Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Accuracy metrics not available in Keras history.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improved Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Keras FFNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for imbalanced labels\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "print('Class weights:', class_weight_dict)\n",
    "\n",
    "# Build improved FFNN with BatchNorm, Dropout, and L2 regularization\n",
    "reg = tfk.regularizers.l2(1e-3)  # Stronger L2 regularization to prevent overfitting\n",
    "input_dim = X_train_np.shape[1]\n",
    "\n",
    "improved_model = tfk.Sequential([\n",
    "    tfl.Input(shape=(input_dim,)),\n",
    "    tfl.Dense(64, activation='relu', kernel_regularizer=reg),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.5),  # Increased dropout to prevent overfitting\n",
    "    tfl.Dense(32, activation='relu', kernel_regularizer=reg),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.5),  # Increased dropout to prevent overfitting\n",
    "    tfl.Dense(16, activation='relu', kernel_regularizer=reg),\n",
    "    tfl.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "improved_model.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tfk.losses.BinaryCrossentropy(),\n",
    "    metrics=[tfk.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "improved_model.summary()\n",
    "\n",
    "callbacks_improved = [\n",
    "    tfkc.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),  # More aggressive early stopping\n",
    "    tfkc.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1),\n",
    "]\n",
    "\n",
    "history_improved = improved_model.fit(\n",
    "    X_train_np, y_train,\n",
    "    validation_data=(X_val_np, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_improved,\n",
    "    class_weight=class_weight_dict,\n",
    ")\n",
    "\n",
    "# Plot loss and accuracy for the improved model\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history_improved.history['loss'], label='Train loss (improved)')\n",
    "plt.plot(history_improved.history['val_loss'], label='Val loss (improved)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary cross-entropy')\n",
    "plt.title('Improved Keras FFNN Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "if 'accuracy' in history_improved.history:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history_improved.history['accuracy'], label='Train acc (improved)')\n",
    "    plt.plot(history_improved.history.get('val_accuracy', []), label='Val acc (improved)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Improved Keras FFNN Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning for improved model (optimize F1 for pop class)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "probs_imp = improved_model.predict(X_test_np).ravel()\n",
    "\n",
    "best_thresh = 0.5\n",
    "best_f1 = -1.0\n",
    "best_stats = None\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "\n",
    "for thr in thresholds:\n",
    "    preds_thr = (probs_imp >= thr).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, preds_thr, average='binary', zero_division=0\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thr\n",
    "        best_stats = (precision, recall, f1)\n",
    "\n",
    "print(f'Best threshold (by F1 for pop class): {best_thresh:.2f}')\n",
    "print(f'Precision: {best_stats[0]:.3f}, Recall: {best_stats[1]:.3f}, F1: {best_stats[2]:.3f}')\n",
    "\n",
    "# Confusion matrix at best threshold\n",
    "best_preds = (probs_imp >= best_thresh).astype(int)\n",
    "cm_imp = confusion_matrix(y_test, best_preds)\n",
    "ConfusionMatrixDisplay(cm_imp, display_labels=['Non-pop', 'Pop']).plot()\n",
    "plt.title(f'Improved Keras FFNN Confusion Matrix (thr={best_thresh:.2f})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Models & Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enhanced Models with Advanced Techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Model: Better Architecture + Feature Engineering + Hyperparameter Tuning\n",
    "# FIXED: Uses EXACT SAME train/test split indices as other models\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Additional feature engineering on the SAME dataframe\n",
    "df_enhanced = df.copy()\n",
    "\n",
    "# Polynomial features for key interactions\n",
    "df_enhanced['popularity_squared'] = df_enhanced['spotify_popularity'] ** 2\n",
    "df_enhanced['tempo_squared'] = df_enhanced['tempo_bpm_synth'] ** 2\n",
    "df_enhanced['popularity_x_tempo'] = df_enhanced['spotify_popularity'] * df_enhanced['tempo_bpm_synth']\n",
    "\n",
    "# Binning features (handle NaN from cut)\n",
    "df_enhanced['popularity_bin'] = pd.cut(df_enhanced['spotify_popularity'], bins=5, labels=False).fillna(-1).astype(int)\n",
    "df_enhanced['tempo_bin'] = pd.cut(df_enhanced['tempo_bpm_synth'], bins=5, labels=False).fillna(-1).astype(int)\n",
    "\n",
    "# Prepare enhanced features (add new polynomial/binned features)\n",
    "enhanced_numeric = numeric_features + ['is_explicit_binary', 'release_month', 'release_decade',\n",
    "                                      'popularity_x_year', 'tempo_x_year',\n",
    "                                      'popularity_squared', 'tempo_squared', 'popularity_x_tempo',\n",
    "                                      'popularity_bin', 'tempo_bin'] + derived_features\n",
    "\n",
    "X_num_enhanced = df_enhanced[enhanced_numeric].copy()\n",
    "X_cat_enhanced = df_enhanced[[cat_feature]].copy()\n",
    "\n",
    "# Scale enhanced features on FULL dataset (same as original)\n",
    "scaler_enhanced = StandardScaler()\n",
    "X_num_enhanced_scaled = scaler_enhanced.fit_transform(X_num_enhanced)\n",
    "\n",
    "# Build enhanced feature matrix\n",
    "X_tab_enhanced = pd.concat([\n",
    "    pd.DataFrame(X_num_enhanced_scaled, columns=X_num_enhanced.columns),\n",
    "    X_cat_dummies.reset_index(drop=True),\n",
    "], axis=1)\n",
    "\n",
    "X_enhanced_full = sp.csr_matrix(X_tab_enhanced.values.astype('float32'))\n",
    "print(f'Enhanced feature dimension: {X_enhanced_full.shape[1]}')\n",
    "\n",
    "# CRITICAL FIX: Use EXACT SAME split as original models\n",
    "# Since we use same random_state=42 and stratify=y, splits will be identical\n",
    "# But to be 100% sure, we recreate the split with same parameters\n",
    "X_train_enh_full, X_temp_enh, y_train_enh, y_temp_enh = train_test_split(\n",
    "    X_enhanced_full, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val_enh, X_test_enh, y_val_enh, y_test_enh = train_test_split(\n",
    "    X_temp_enh, y_temp_enh, test_size=0.5, random_state=42, stratify=y_temp_enh\n",
    ")\n",
    "\n",
    "# Convert to numpy\n",
    "X_train_enh_np = X_train_enh_full.toarray().astype('float32')\n",
    "X_val_enh_np = X_val_enh.toarray().astype('float32')\n",
    "X_test_enh_np = X_test_enh.toarray().astype('float32')\n",
    "\n",
    "# VERIFY: Test sets should be identical (same random_state, same stratify)\n",
    "assert np.array_equal(y_test, y_test_enh), \"Test sets don't match! This is a bug.\"\n",
    "assert np.array_equal(y_train, y_train_enh), \"Train sets don't match! This is a bug.\"\n",
    "print(f'✅ Verified: Using SAME train/test split as other models')\n",
    "print(f'  Train: {X_train_enh_np.shape[0]} samples')\n",
    "print(f'  Val: {X_val_enh_np.shape[0]} samples')\n",
    "print(f'  Test: {X_test_enh_np.shape[0]} samples')\n",
    "\n",
    "input_dim_enhanced = X_train_enh_np.shape[1]\n",
    "print(f'Input dimension (enhanced): {input_dim_enhanced}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced FFNN with Better Architecture + Batch Normalization\n",
    "# Improved: Larger network to match deeper model performance\n",
    "\n",
    "reg_enhanced = tfk.regularizers.l2(1e-4)\n",
    "\n",
    "model_enhanced = tfk.Sequential([\n",
    "    tfl.Input(shape=(input_dim_enhanced,)),\n",
    "    tfl.Dense(128, activation='relu', kernel_regularizer=reg_enhanced),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.4),\n",
    "    tfl.Dense(64, activation='relu', kernel_regularizer=reg_enhanced),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.3),\n",
    "    tfl.Dense(32, activation='relu', kernel_regularizer=reg_enhanced),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_enhanced.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=1e-3),  # Same as deeper model\n",
    "    loss=tfk.losses.BinaryCrossentropy(),\n",
    "    metrics=[tfk.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "model_enhanced.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train enhanced model with better callbacks + class weights\n",
    "\n",
    "# Compute class weights for imbalanced labels (like deeper model)\n",
    "from sklearn.utils import class_weight\n",
    "classes_enh = np.unique(y_train_enh)\n",
    "weights_enh = class_weight.compute_class_weight(class_weight='balanced', classes=classes_enh, y=y_train_enh)\n",
    "class_weight_dict_enh = {int(c): float(w) for c, w in zip(classes_enh, weights_enh)}\n",
    "print(f'Class weights: {class_weight_dict_enh}')\n",
    "\n",
    "callbacks_enhanced = [\n",
    "    tfkc.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    tfkc.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
    "    tfkc.ModelCheckpoint('best_enhanced_model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "history_enhanced = model_enhanced.fit(\n",
    "    X_train_enh_np, y_train_enh,\n",
    "    validation_data=(X_val_enh_np, y_val_enh),\n",
    "    epochs=200,  # More epochs for better convergence\n",
    "    batch_size=256,  # Larger batch for stability\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_enhanced,\n",
    "    class_weight=class_weight_dict_enh  # Handle class imbalance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate enhanced model\n",
    "\n",
    "enhanced_probs = model_enhanced.predict(X_test_enh_np).ravel()\n",
    "enhanced_preds = (enhanced_probs >= 0.5).astype(int)\n",
    "\n",
    "print('\\nEnhanced Model Classification Report:')\n",
    "print(classification_report(y_test, enhanced_preds, digits=3))\n",
    "\n",
    "enhanced_auc = roc_auc_score(y_test, enhanced_probs)\n",
    "print(f'Enhanced Model ROC AUC: {enhanced_auc:.3f}')\n",
    "\n",
    "cm_enhanced = confusion_matrix(y_test, enhanced_preds)\n",
    "ConfusionMatrixDisplay(cm_enhanced, display_labels=['Non-pop', 'Pop']).plot()\n",
    "plt.title('Enhanced Model Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvements Summary\n",
    "\n",
    "**Enhanced Model includes:**\n",
    "\n",
    "1. **Better Feature Engineering:**\n",
    "   - Polynomial features (popularity², tempo², popularity×tempo)\n",
    "   - Binned features (popularity_bin, tempo_bin)\n",
    "   - More interaction features\n",
    "\n",
    "2. **Improved Architecture:**\n",
    "   - Larger network: 64→32→16 neurons\n",
    "   - Batch Normalization for stable training\n",
    "   - Progressive dropout (0.4→0.3→0.2)\n",
    "\n",
    "3. **Better Training:**\n",
    "   - Lower learning rate (5e-4)\n",
    "   - Model checkpointing\n",
    "   - More epochs (150) with early stopping\n",
    "   - Smaller batch size (128) for better gradients\n",
    "\n",
    "**Expected improvements:**\n",
    "- Better feature representation\n",
    "- More stable training\n",
    "- Higher AUC (target: >0.90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper FFNN with enhanced architecture\n",
    "input_dim = X_train_np.shape[1]\n",
    "print('Input dimension:', input_dim)\n",
    "\n",
    "deeper_model = tfk.Sequential([\n",
    "    tfl.Input(shape=(input_dim,)),\n",
    "    tfl.Dense(128, activation='relu', kernel_regularizer=tfk.regularizers.l2(1e-4)),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.4),\n",
    "    tfl.Dense(64, activation='relu', kernel_regularizer=tfk.regularizers.l2(1e-4)),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.3),\n",
    "    tfl.Dense(32, activation='relu', kernel_regularizer=tfk.regularizers.l2(1e-4)),\n",
    "    tfl.BatchNormalization(),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(16, activation='relu'),\n",
    "    tfl.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "deeper_model.compile(\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tfk.losses.BinaryCrossentropy(),\n",
    "    metrics=[tfk.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "deeper_model.summary()\n",
    "\n",
    "# Compute class weights for imbalanced labels\n",
    "from sklearn.utils import class_weight\n",
    "classes = np.unique(y_train)\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "\n",
    "callbacks_deeper = [\n",
    "    tfkc.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "    tfkc.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1),\n",
    "]\n",
    "\n",
    "history_deeper = deeper_model.fit(\n",
    "    X_train_np, y_train,\n",
    "    validation_data=(X_val_np, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_deeper,\n",
    "    class_weight=class_weight_dict,\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_deeper.history['loss'], label='Train loss')\n",
    "plt.plot(history_deeper.history['val_loss'], label='Val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary cross-entropy')\n",
    "plt.title('Deeper FFNN Training vs Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "if 'accuracy' in history_deeper.history:\n",
    "    plt.plot(history_deeper.history['accuracy'], label='Train accuracy')\n",
    "    plt.plot(history_deeper.history.get('val_accuracy', []), label='Val accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Deeper FFNN Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate deeper model on test set\n",
    "deeper_probs = deeper_model.predict(X_test_np).ravel()\n",
    "deeper_preds = (deeper_probs >= 0.5).astype(int)\n",
    "\n",
    "print('\\nDeeper FFNN classification report (0 = non-pop, 1 = pop):')\n",
    "print(classification_report(y_test, deeper_preds, digits=3))\n",
    "\n",
    "try:\n",
    "    deeper_auc = roc_auc_score(y_test, deeper_probs)\n",
    "    print(f'Deeper FFNN ROC AUC: {deeper_auc:.3f}')\n",
    "except Exception as e:\n",
    "    print('Could not compute ROC AUC:', e)\n",
    "\n",
    "cm_deeper = confusion_matrix(y_test, deeper_preds)\n",
    "ConfusionMatrixDisplay(cm_deeper, display_labels=['Non-pop', 'Pop']).plot()\n",
    "plt.title('Deeper FFNN Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all feature names being used\n",
    "print('=== ALL FEATURES IN THE MODEL ===\\n')\n",
    "print(f'Numeric features ({len(X_num.columns)}):')\n",
    "for feat in X_num.columns:\n",
    "    print(f'  - {feat}')\n",
    "\n",
    "print(f'\\nCategorical features - one-hot encoded ({X_cat_dummies.shape[1]}):')\n",
    "for feat in X_cat_dummies.columns:\n",
    "    print(f'  - {feat}')\n",
    "\n",
    "print(f'\\nTF-IDF Genre features: DISABLED (removed to prevent data leakage)')\n",
    "\n",
    "print(f'\\nTotal features: {X_full.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FFNN Models: ROC Curves\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Baseline FFNN\n",
    "try:\n",
    "    if 'probs' in globals():\n",
    "        fpr_base, tpr_base, _ = roc_curve(y_test, probs)\n",
    "        roc_base = auc(fpr_base, tpr_base)\n",
    "        plt.plot(fpr_base, tpr_base, label=f'Baseline FFNN (AUC={roc_base:.3f})')\n",
    "except Exception as e:\n",
    "    print('Could not plot baseline FFNN ROC:', e)\n",
    "\n",
    "# Improved FFNN\n",
    "try:\n",
    "    if 'probs_imp' in globals():\n",
    "        fpr_imp, tpr_imp, _ = roc_curve(y_test, probs_imp)\n",
    "        roc_imp = auc(fpr_imp, tpr_imp)\n",
    "        plt.plot(fpr_imp, tpr_imp, label=f'Improved FFNN (AUC={roc_imp:.3f})')\n",
    "except Exception as e:\n",
    "    print('Could not plot improved FFNN ROC:', e)\n",
    "\n",
    "# Deeper FFNN\n",
    "try:\n",
    "    if 'deeper_probs' in globals():\n",
    "        fpr_deep, tpr_deep, _ = roc_curve(y_test, deeper_probs)\n",
    "        roc_deep = auc(fpr_deep, tpr_deep)\n",
    "        plt.plot(fpr_deep, tpr_deep, label=f'Deeper FFNN (AUC={roc_deep:.3f})')\n",
    "except Exception as e:\n",
    "    print('Could not plot deeper FFNN ROC:', e)\n",
    "\n",
    "# Enhanced FFNN\n",
    "try:\n",
    "    if 'enhanced_probs' in globals():\n",
    "        fpr_enh, tpr_enh, _ = roc_curve(y_test, enhanced_probs)\n",
    "        roc_enh = auc(fpr_enh, tpr_enh)\n",
    "        plt.plot(fpr_enh, tpr_enh, label=f'Enhanced FFNN (AUC={roc_enh:.3f})', linewidth=2)\n",
    "except Exception as e:\n",
    "    print('Could not plot enhanced FFNN ROC:', e)\n",
    "\n",
    "# Random baseline\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random', alpha=0.5)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: FFNN Models Comparison')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-music-proj-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
